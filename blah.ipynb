{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the dataset\n",
    "Cleaning the content column, tokenizing, stemming.\n",
    "Dropping empty rows, unnecessary columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '995,000_rows.csv'\n",
    "df = pd.read_csv(filename, usecols=['content', 'type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Redacts URLs, dates, email addresses and numbers in a given text input, as well as converting text to lower case and removing tabs, newlines, and spaces following other spaces\"\"\"\n",
    "    text = str(text)\n",
    "    date_exp =  {\n",
    "                \"year_mm_dd\" : re.compile(r'[^\\d]{1}([0-9]{2,4})[\\s\\/\\.\\-\\\\]?([0-1]{1}[0-9]{1})[\\s\\/\\.\\-\\\\]?([0-3]{1}[0-9]{1})\\s?([\\d]{2}:[\\d]{2}:[\\d]{2}\\.[\\d]{6})?', re.MULTILINE),   \n",
    "                \"dd_mm_year\" : re.compile(r'[^\\d]{1}([0-3]{1}[0-9]{1})[\\s\\/\\.\\-\\\\]?([0-1]{1}[0-9]{1})[\\s\\/\\.\\-\\\\]?([0-9]{2,4})\\s?([\\d]{2}:[\\d]{2}:[\\d]{2}\\.[\\d]{6})?', re.MULTILINE),\n",
    "                \"mm_dd_year\" : re.compile(r'[^\\d]{1}([0-1]{1}[0-9]{1})[\\s\\/\\.\\-\\\\]?([0-3]{1}[0-9]{1})[\\s\\/\\.\\-\\\\]?([0-9]{2,4})\\s?([\\d]{2}:[\\d]{2}:[\\d]{2}\\.[\\d]{6})?', re.MULTILINE),\n",
    "                \"year_mm_dd_time\" : re.compile(r'[^\\d]{1}([0-9]{2,4})[\\s\\/\\.\\-\\\\]?([0-1]{1}[0-9]{1})[\\s\\/\\.\\-\\\\]?([0-3]{1}[0-9]{1})\\s?([\\d]{2}:[\\d]{2}:[\\d]{2}\\.[\\d]{6})?', re.MULTILINE),\n",
    "                \"dd_mm_year_time\" : re.compile(r'[^\\d]{1}([0-3]{1}[0-9]{1})[\\s\\/\\.\\-\\\\]?([0-1]{1}[0-9]{1})[\\s\\/\\.\\-\\\\]?([0-9]{2,4})\\s?([\\d]{2}:[\\d]{2}:[\\d]{2}\\.[\\d]{6})?', re.MULTILINE),\n",
    "                \"mm_dd_year_time\" : re.compile(r'[^\\d]{1}([0-1]{1}[0-9]{1})[\\s\\/\\.\\-\\\\]?([0-3]{1}[0-9]{1})[\\s\\/\\.\\-\\\\]?([0-9]{2,4})\\s?([\\d]{2}:[\\d]{2}:[\\d]{2}\\.[\\d]{6})?', re.MULTILINE),\n",
    "                \"year_mm_dd_hh_mm\" : re.compile(r'[^\\d]{1}([0-9]{2,4})[\\s\\/\\.\\-\\\\]?([0-1]{1}[0-9]{1})[\\s\\/\\.\\-\\\\]?([0-3]{1}[0-9]{1})\\s?([\\d]{2}:[\\d]{2})', re.MULTILINE),\n",
    "                \"dd_mm_year_hh_mm\" : re.compile(r'[^\\d]{1}([0-3]{1}[0-9]{1})[\\s\\/\\.\\-\\\\]?([0-1]{1}[0-9]{1})[\\s\\/\\.\\-\\\\]?([0-9]{2,4})\\s?([\\d]{2}:[\\d]{2})', re.MULTILINE),\n",
    "                \"mm_dd_year_hh_mm\" : re.compile(r'[^\\d]{1}([0-1]{1}[0-9]{1})[\\s\\/\\.\\-\\\\]?([0-3]{1}[0-9]{1})[\\s\\/\\.\\-\\\\]?([0-9]{2,4})\\s?([\\d]{2}:[\\d]{2})', re.MULTILINE),\n",
    "                \"year_mm_dd_hh_mm_ss\" : re.compile(r'[^\\d]{1}([0-9]{2,4})[\\s\\/\\.\\-\\\\]?([0-1]{1}[0-9]{1})[\\s\\/\\.\\-\\\\]?([0-3]{1}[0-9]{1})\\s?([\\d]{2}:[\\d]{2}:[\\d]{2})', re.MULTILINE),\n",
    "                \"dd_mm_year_hh_mm_ss\" : re.compile(r'[^\\d]{1}([0-3]{1}[0-9]{1})[\\s\\/\\.\\-\\\\]?([0-1]{1}[0-9]{1})[\\s\\/\\.\\-\\\\]?([0-9]{2,4})\\s?([\\d]{2}:[\\d]{2}:[\\d]{2})', re.MULTILINE),\n",
    "                \"mm_dd_year_hh_mm_ss\" : re.compile(r'[^\\d]{1}([0-1]{1}[0-9]{1})[\\s\\/\\.\\-\\\\]?([0-3]{1}[0-9]{1})[\\s\\/\\.\\-\\\\]?([0-9]{2,4})\\s?([\\d]{2}:[\\d]{2}:[\\d]{2})', re.MULTILINE),\n",
    "                }\n",
    "    num_exp = re.compile('[0-9]+[,.]?[0-9]*', re.MULTILINE)\n",
    "    num2_exp = re.compile(r'([0-9]+)((st)?(nd)?(rd)?(th)?(st)?){1}')\n",
    "    url_exp = re.compile(r'((h{1}t{2}p{1}s?\\:{1}\\/{2})|(w{3}\\.{1})){0,2}[^,\\s]*\\.[a-zA-Z]{2,}[^,\\s]*', re.MULTILINE)\n",
    "    email_exp = re.compile(r'[^,\\s\\/]*@{1}[^,\\s\\/]*\\.[a-zA-Z]{2,3}', re.MULTILINE)\n",
    "    space_exp = re.compile(r'([\\s]{2,})|[\\t]|[\\n]+', re.MULTILINE)\n",
    "    punctuation_exp = re.compile(r'[^\\w\\s]', re.MULTILINE)\n",
    "\n",
    "    text = text.lower()\n",
    "    for exp in date_exp.values():\n",
    "        text = exp.sub('datetoken', text) #Replace dates before numbers\n",
    "    text = num2_exp.sub('numtoken', text)\n",
    "    text = num_exp.sub('numtoken', text)\n",
    "    text = url_exp.sub('urltoken', text)\n",
    "    text = email_exp.sub('emailtoken', text)\n",
    "    text = space_exp.sub(' ', text)\n",
    "    text = punctuation_exp.sub(' ', text)\n",
    "    return text\n",
    "\n",
    "def clean_text_series(series):\n",
    "    return series.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_chunker(df, chunksize):\n",
    "    list_df = np.array_split(df, math.ceil(len(df) / chunksize))\n",
    "    del df\n",
    "    j = 1\n",
    "    for df in list_df:\n",
    "        print(f\"Processing chunk {j} of {len(list_df)}:\")\n",
    "        # Check if chunk parquet already exists\n",
    "        try:\n",
    "            pq.read_table(f\"chunk_{j}.parquet\").to_pandas()\n",
    "            print(f\"Chunk {j} already processed!\", flush=True)\n",
    "            chunk = pd.read_parquet(f\"chunk_{j}.parquet\")\n",
    "            j += 1\n",
    "            continue\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        print(\"Cleaning content...\", flush=True)\n",
    "        df['content'] = clean_text_series(df['content'])\n",
    "        print(\" \", end=\"\\r\", flush=True)\n",
    "\n",
    "        print(\"Calculating features...\", end=\"\\r\", flush=True)\n",
    "        df['length'] = df['content'].apply(len)\n",
    "        df['distinct_words'] = df['content'].apply(lambda x: set(x.split()))\n",
    "        df['length_distinct_words'] = df['distinct_words'].apply(len)\n",
    "        df['group'] = df['type'].apply(lambda x: 1 if x in ['fake', 'satire', 'bias', 'conspiracy', 'junksci', 'hate'] else 0)\n",
    "\n",
    "        def f_NUM(x):\n",
    "            count = 0\n",
    "            for word in x.split():\n",
    "                if word == 'numtoken':\n",
    "                    count += 1\n",
    "            return count\n",
    "\n",
    "        def f_URL(x):\n",
    "            count = 0\n",
    "            for word in x.split():\n",
    "                if word == 'urltoken':\n",
    "                    count += 1\n",
    "            return count\n",
    "            \n",
    "        def f_EMAIL(x):\n",
    "            count = 0\n",
    "            for word in x.split():\n",
    "                if word == 'emailtoken':\n",
    "                    count += 1\n",
    "            return count\n",
    "\n",
    "        def f_DATE(x):\n",
    "            count = 0\n",
    "            for word in x.split():\n",
    "                if word == 'datetoken':\n",
    "                    count += 1\n",
    "            return count\n",
    "\n",
    "        df['numtokens'] = df['content'].apply(f_NUM)\n",
    "        df['urltokens'] = df['content'].apply(f_URL)\n",
    "        df['emailtokens'] = df['content'].apply(f_EMAIL)\n",
    "        df['datetokens'] = df['content'].apply(f_DATE)\n",
    "\n",
    "        print(\"\\n\", end=\"\\r\", flush=True)\n",
    "\n",
    "        print(\"Saving chunk...\", end=\"\\r\", flush=True)\n",
    "        df.to_parquet(f\"chunk_{j}.parquet\")\n",
    "        print(f\"Chunk {j} done!\", flush=True)\n",
    "        \n",
    "        j += 1\n",
    "    df = pd.concat([pd.read_parquet(f\"chunk_{j}.parquet\") for j in range(1, len(list_df) + 1)])\n",
    "    del list_df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fesso\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1 of 20:\n",
      "Cleaning content...\n",
      "Calculating features...\n",
      "Chunk 1 done!..\n",
      "Processing chunk 2 of 20:\n",
      "Cleaning content...\n",
      "Calculating features...\n",
      "Chunk 2 done!..\n",
      "Processing chunk 3 of 20:\n",
      "Cleaning content...\n",
      "Calculating features...\n",
      "Chunk 3 done!..\n",
      "Processing chunk 4 of 20:\n",
      "Cleaning content...\n",
      "Calculating features...\n",
      "Chunk 4 done!..\n",
      "Processing chunk 5 of 20:\n",
      "Cleaning content...\n",
      "Calculating features...\n",
      "Chunk 5 done!..\n",
      "Processing chunk 6 of 20:\n",
      "Cleaning content...\n",
      "Calculating features...\n",
      "Chunk 6 done!..\n",
      "Processing chunk 7 of 20:\n",
      "Cleaning content...\n",
      "Calculating features...\n",
      "Chunk 7 done!..\n",
      "Processing chunk 8 of 20:\n",
      "Cleaning content...\n",
      "Calculating features...\n",
      "Chunk 8 done!..\n",
      "Processing chunk 9 of 20:\n",
      "Cleaning content...\n",
      "Calculating features...\n",
      "Chunk 9 done!..\n",
      "Processing chunk 10 of 20:\n",
      "Cleaning content...\n",
      "Calculating features...\n",
      "Chunk 10 done!.\n",
      "Processing chunk 11 of 20:\n",
      "Cleaning content...\n",
      "Calculating features...\n",
      "Chunk 11 done!.\n",
      "Processing chunk 12 of 20:\n",
      "Cleaning content...\n",
      "Calculating features...\n",
      "Chunk 12 done!.\n",
      "Processing chunk 13 of 20:\n",
      "Cleaning content...\n",
      "Calculating features...\n",
      "Chunk 13 done!.\n",
      "Processing chunk 14 of 20:\n",
      "Cleaning content...\n",
      "Calculating features...\n",
      "Chunk 14 done!.\n",
      "Processing chunk 15 of 20:\n",
      "Cleaning content...\n",
      "Calculating features...\n",
      "Chunk 15 done!.\n",
      "Processing chunk 16 of 20:\n",
      "Cleaning content...\n",
      "Calculating features...\n",
      "Chunk 16 done!.\n",
      "Processing chunk 17 of 20:\n",
      "Cleaning content...\n",
      "Calculating features...\n",
      "Chunk 17 done!.\n",
      "Processing chunk 18 of 20:\n",
      "Cleaning content...\n",
      "Calculating features...\n",
      "Chunk 18 done!.\n",
      "Processing chunk 19 of 20:\n",
      "Cleaning content...\n",
      "Calculating features...\n",
      "Chunk 19 done!.\n",
      "Processing chunk 20 of 20:\n",
      "Cleaning content...\n",
      "Calculating features...\n",
      "Chunk 20 done!.\n"
     ]
    }
   ],
   "source": [
    "df = df_chunker(df, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>group</th>\n",
       "      <th>numtokens</th>\n",
       "      <th>urltokens</th>\n",
       "      <th>emailtokens</th>\n",
       "      <th>datetokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2132</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>997</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4903</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36816</td>\n",
       "      <td>1</td>\n",
       "      <td>960</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994995</th>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994996</th>\n",
       "      <td>2132</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994997</th>\n",
       "      <td>6445</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994998</th>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994999</th>\n",
       "      <td>775</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>994999 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        length  group  numtokens  urltokens  emailtokens  datetokens\n",
       "0         2132      0          2          0            0           0\n",
       "1          997      1          4          2            0           0\n",
       "2          189      1          2          1            0           0\n",
       "3         4903      0          6          2            0           0\n",
       "4        36816      1        960          3            0           1\n",
       "...        ...    ...        ...        ...          ...         ...\n",
       "994995     171      1          0          0            0           0\n",
       "994996    2132      0          2          0            0           0\n",
       "994997    6445      0         27          5            0           0\n",
       "994998     121      0          0          0            0           0\n",
       "994999     775      1          0          0            0           0\n",
       "\n",
       "[994999 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['content'], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test  = train_test_split(df['content'], df['group'], test_size=0.2, random_state=42)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "577163    to the editor  re  foreign stimulus   op ed  s...\n",
       "925049    plus one article on google plus  thanks to ali...\n",
       "903173    mr  morris  who is now numtoken  says his lush...\n",
       "610830    hideous absinthe a history of the devil in a b...\n",
       "219994    gary cahill could leave chelsea at the end of ...\n",
       "                                ...                        \n",
       "685965    it started out as a love song  alanis morisset...\n",
       "981068    royal oil and vinegar bottle set with stainles...\n",
       "214052    there have been many times where i have gone o...\n",
       "392662    yesterday  i received a threatening letter fro...\n",
       "15486     a variety of executive orders have been signed...\n",
       "Name: content, Length: 199000, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert the text to a bag-of-words representation\n",
    "vectorizer = CountVectorizer(analyzer='word', stop_words='english')\n",
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_test = vectorizer.transform(x_test)\n",
    "x_val = vectorizer.transform(x_val) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fesso\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a logistic regression classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = classifier.predict(x_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8514472361809046\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['content'].apply(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = {}\n",
    "for content in df['content']:\n",
    "    for word in content:\n",
    "        if word in word_counts:\n",
    "            word_counts[word] += 1\n",
    "        else:\n",
    "            word_counts[word] = 1\n",
    "\n",
    "top_10k = sorted(word_counts, key=word_counts.get, reverse=True)[:10000]\n",
    "\n",
    "#df['content_filtered'] = df['content'].apply(lambda x: [word for word in x if word in top_10k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations\n",
    "## Articles of each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(111)\n",
    "ax1.bar(df[\"type\"].value_counts().index, df[\"type\"].value_counts().values)\n",
    "ax1.set_title(f'Article types')\n",
    "ax1.set_xlabel('Types')\n",
    "plt.xticks(rotation=45)\n",
    "ax1.set_ylabel('# of articles')\n",
    "fig1.savefig(f'data\\\\articles_of_each_type.png')\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for type in df['type'].unique():\n",
    "    name = f'{type}_df'\n",
    "    globals()[name] = df[df['type'] == type]\n",
    "\n",
    "    print(f'Articles of type {type}: {len(globals()[name])}')\n",
    "\n",
    "    print(f'{type} mean length: {globals()[name][\"length\"].mean()}')\n",
    "    print(f'{type} median length: {globals()[name][\"length\"].median()}')\n",
    "\n",
    "    print(f'{type} mean distinct words: {globals()[name][\"length_distinct_words\"].mean()}')\n",
    "    print(f'{type} median distinct words: {globals()[name][\"length_distinct_words\"].median()}')\n",
    "\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Article lengths vs. number of distinct words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate global min and max for length and length_distinct_words\n",
    "global_min_length = df['length'].min()\n",
    "global_max_length = df['length'].max()\n",
    "global_min_length_distinct_words = df['length_distinct_words'].min()\n",
    "global_max_length_distinct_words = df['length_distinct_words'].max()\n",
    "\n",
    "# Main plot with all data points\n",
    "fig1, ax1 = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Use a color map to automatically assign colors\n",
    "color_map = plt.get_cmap('tab10')\n",
    "\n",
    "# Plot each type with a different color and set the size of the dots\n",
    "dot_size = 1  # Adjust this value to change the size of the dots\n",
    "for i, article_type in enumerate(df['type'].unique()):\n",
    "    type_df = df[df['type'] == article_type]\n",
    "    ax1.scatter(type_df['length_distinct_words'], type_df['length'], color=color_map(i), label=article_type, s=dot_size)\n",
    "\n",
    "ax1.set_title('Article length vs number of distinct words')\n",
    "ax1.set_xlabel('Number of distinct words')\n",
    "ax1.set_ylabel('Article length')\n",
    "ax1.legend()\n",
    "ax1.set_xlim(global_min_length_distinct_words, global_max_length_distinct_words)\n",
    "ax1.set_ylim(global_min_length, global_max_length)\n",
    "\n",
    "# Create a new figure for the grid of subplots\n",
    "num_types = len(df['type'].unique())\n",
    "ncols = 2\n",
    "nrows = (num_types + 1) // ncols  # Calculate the number of rows needed\n",
    "\n",
    "fig2, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 5 * nrows))\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each type in a separate subplot\n",
    "for i, article_type in enumerate(df['type'].unique()):\n",
    "    type_df = df[df['type'] == article_type]\n",
    "    ax = axes[i]\n",
    "    ax.scatter(type_df['length_distinct_words'], type_df['length'], color=color_map(i), label=article_type, s=dot_size)\n",
    "    ax.set_title(f'{article_type}')\n",
    "    ax.set_xlabel('Number of distinct words')\n",
    "    ax.set_ylabel('Article length')\n",
    "    ax.legend()\n",
    "    ax.set_xlim(global_min_length_distinct_words, global_max_length_distinct_words)\n",
    "    ax.set_ylim(global_min_length, global_max_length)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig2.delaxes(axes[j])\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figures\n",
    "fig1.savefig('data/article_length_vs_distinct_words.png')\n",
    "fig2.savefig('data/article_length_vs_distinct_words_by_type.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions of article lengths pr. type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory if it does not exist\n",
    "output_dir = 'data/article_length_distributions'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Calculate global min and max for length and log(length)\n",
    "global_min_length = df['length'].min()\n",
    "global_max_length = df['length'].max()\n",
    "global_min_log_length = np.log(df['length']).min()\n",
    "global_max_log_length = np.log(df['length']).max()\n",
    "\n",
    "for article_type in df['type'].unique():\n",
    "    fig1 = plt.figure(figsize=(10, 5))\n",
    "    # Adding two subplots side by side\n",
    "    ax1 = fig1.add_subplot(1, 2, 1)\n",
    "    ax2 = fig1.add_subplot(1, 2, 2)\n",
    "    \n",
    "    type_df = df[df['type'] == article_type]\n",
    "    \n",
    "    # The first subplot shows the distribution of the length of the articles\n",
    "    ax1.hist(type_df['length'], bins=100)\n",
    "    ax1.set_title(f'{article_type} article length distribution')\n",
    "    ax1.set_xlabel('Article length')\n",
    "    ax1.set_ylabel('# of articles')\n",
    "    ax1.set_xlim(global_min_length, global_max_length)  # Set uniform x-axis limits\n",
    "\n",
    "    # The second subplot shows the distribution of the log of the length of the articles to better visualize the distribution\n",
    "    ax2.hist(np.log(type_df['length']), bins=100)\n",
    "    ax2.set_title(f'{article_type} article length distribution (log scale)')\n",
    "    ax2.set_xlabel('log(Article length)')\n",
    "    ax2.set_ylabel('# of articles')\n",
    "    ax2.set_xlim(global_min_log_length, global_max_log_length)  # Set uniform x-axis limits\n",
    "\n",
    "    fig1.savefig(f'{output_dir}/{article_type}_article_length_distribution.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = {}\n",
    "for content in df['content']:\n",
    "    for word in content:\n",
    "        if word in word_counts:\n",
    "            word_counts[word] += 1\n",
    "        else:\n",
    "            word_counts[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [bias_df, clickbait_df, conspiracy_df, fake_df, hate_df, junksci_df, political_df, reliable_df, rumor_df, satire_df, unknown_df, unreliable_df]:\n",
    "    type = df['type'].unique()[0]\n",
    "    name = f'{type}_wordlist'\n",
    "    word_counts = {}\n",
    "    for content in df['content']:\n",
    "        for word in content:\n",
    "            if word in word_counts:\n",
    "                word_counts[word] += 1\n",
    "            else:\n",
    "                word_counts[word] = 1\n",
    "    globals()[name] = word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common words by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize=(20, 5))\n",
    "ax1 = fig1.add_subplot(111)\n",
    "ax1.bar(*zip(*sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:10]))\n",
    "ax1.set_title('10 most common words')\n",
    "ax1.set_xlabel('Words')\n",
    "plt.xticks(rotation=45)\n",
    "ax1.set_ylabel('# of occurrences')\n",
    "fig1.savefig('data/10_most_common_words.png')\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [bias_df, clickbait_df, conspiracy_df, fake_df, hate_df, junksci_df, political_df, reliable_df, rumor_df, satire_df, unknown_df, unreliable_df]:\n",
    "    type = df['type'].unique()[0]\n",
    "    fig1 = plt.figure(figsize=(20, 5))\n",
    "    ax1 = fig1.add_subplot(111)\n",
    "    ax1.bar(*zip(*sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:10]))\n",
    "    ax1.set_title(f'{type} articles 10 most common words')\n",
    "    ax1.set_xlabel('Words')\n",
    "    plt.xticks(rotation=45)\n",
    "    ax1.set_ylabel('# of occurrences')\n",
    "    fig1.savefig(f'data/{type}10_most_common_words.png')\n",
    "    fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    if x in ['political', 'clickbait', 'reliable']: return 1\n",
    "    else: return 0 \n",
    "\n",
    "df['Group'] = df['type'].apply(f1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f3(x):\n",
    "    list = []\n",
    "    for word in x:\n",
    "        list.append(word)\n",
    "    string = ' '.join(list)\n",
    "    return string\n",
    "df['content'] = df['content'].apply(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentlist = df['content'].tolist()\n",
    "grouplist = df['Group'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0', 'id', 'domain', 'url', 'scraped_at', 'inserted_at', 'updated_at', 'meta_keywords','source', 'title', 'distinct_words', 'type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word_counts = sorted(train_word_counts.items(), key=lambda x: x[1], reverse=True)[:10000]\n",
    "len(train_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
